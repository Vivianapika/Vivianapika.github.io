{
  "hash": "17dd9dc329f2c1250f66357a990619ea",
  "result": {
    "markdown": "---\ntitle: Learning spaCy\nauthor: Vivian\ndate: '2024-06-12'\ncategories:\n  - nlp\nimage: image.jpg\ncode-fold: true\n---\n\n[Spacy 101](https://spacy.io/usage/spacy-101)\n\n## Pipeline and Architecture\n![pipeline](pipeline.svg){width=300}\n![Architecture](architecture.svg)\n\n## Vocab, Lexemes and StringStore\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Shared vocab and string store\nnlp.vocab.strings.add(\"coffee\")\ncoffee_hash = nlp.vocab.strings[\"coffee\"]\ncoffee_string = nlp.vocab.strings[coffee_hash]\ndoc = nlp(\"I love coffee\")\nprint(\"hash value:\", nlp.vocab.strings[\"coffee\"])\nprint(\"string value:\", nlp.vocab.strings[3197928453018144401])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhash value: 3197928453018144401\nstring value: coffee\n```\n:::\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Lexemes: entries in the vocabulary\ndoc = nlp(\"I love coffee\")\nlexeme = nlp.vocab[\"coffee\"]\n# Print the lexical attributes\nprint(lexeme.text, lexeme.orth, lexeme.is_alpha)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncoffee 3197928453018144401 True\n```\n:::\n:::\n\n\n## Doc, Span and Token\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Create an nlp object\nnlp = spacy.blank(\"en\")\n\n# Import the Doc and Span classes\nfrom spacy.tokens import Doc, Span\n\n# The words and spaces to create the doc from\nwords = [\"I\", \"like\", \"David\", \"Bowie\"]\nspaces = [True, True, True, False]\n\n# Create a doc manually\ndoc = Doc(nlp.vocab, words=words, spaces=spaces)\nprint(doc.text)\n\n# Create a span manually\n# span = Span(doc, 0, 2)\n\n# Create a span with a label\n# Create a span for \"David Bowie\" from the doc and assign it the label \"PERSON\"\nspan_with_label = Span(doc, 2, 4, label=\"PERSON\")\nprint(span_with_label.text, span_with_label.label_)\n\n# Add span to the doc.ents (doc's entities)\ndoc.ents = [span_with_label]\n\n# Print entities' text and labels\nprint([(ent.text, ent.label_) for ent in doc.ents])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nI like David Bowie\nDavid Bowie PERSON\n[('David Bowie', 'PERSON')]\n```\n:::\n:::\n\n\n## Data structures best practices\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Berlin looks like a nice city\")\n\nfor token in doc:\n    # Check if the current token is a proper noun\n    if token.pos_ == \"PROPN\":\n        # Check if the next token is a verb\n        if token.i + 1 < len(doc):\n            if doc[token.i + 1].pos_ == \"VERB\":\n                result = token.text\n                print(\"Found proper noun before a verb:\", result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFound proper noun before a verb: Berlin\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}